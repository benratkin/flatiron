{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In Depth A/B Testing - Lab\n",
    "\n",
    "## Introduction\n",
    "\n",
    "In this lab, you'll explore a survey from Kaggle regarding budding data scientists. With this, you'll form some initial hypotheses, and test them using the tools you've acquired to date. \n",
    "\n",
    "## Objectives\n",
    "\n",
    "You will be able to:\n",
    "* Conduct t-tests and an ANOVA on a real-world dataset and interpret the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Dataset and Perform a Brief Exploration\n",
    "\n",
    "The data is stored in a file called **multipleChoiceResponses_cleaned.csv**. Feel free to check out the original dataset referenced at the bottom of this lab, although this cleaned version will undoubtedly be easier to work with. Additionally, meta-data regarding the questions is stored in a file name **schema.csv**. Load in the data itself as a Pandas DataFrame, and take a moment to briefly get acquainted with it.\n",
    "\n",
    "> Note: If you can't get the file to load properly, try changing the encoding format as in `encoding='latin1'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import flatiron_stats\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the meta-dataset\n",
    "df_schema = pd.read_csv('schema.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv('multipleChoiceResponses_cleaned.csv', encoding='latin1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wages and Education\n",
    "\n",
    "You've been asked to determine whether education is impactful to salary. Develop a hypothesis test to compare the salaries of those with Master's degrees to those with Bachelor's degrees. Are the two statistically different according to your results?\n",
    "\n",
    "> Note: The relevant features are stored in the 'FormalEducation' and 'AdjustedCompensation' features.\n",
    "\n",
    "You may import the functions stored in the `flatiron_stats.py` file to help perform your hypothesis tests. It contains the stats functions that you previously coded: `welch_t(a,b)`, `welch_df(a, b)`, and `p_value(a, b, two_sided=False)`. \n",
    "\n",
    "Note that `scipy.stats.ttest_ind(a, b, equal_var=False)` performs a two-sided Welch's t-test and that p-values derived from two-sided tests are two times the p-values derived from one-sided tests. See the [documentation](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.ttest_ind.html) for more information.    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$H_0$: $\\mu_b$ = $\\mu_m$ \n",
    "\n",
    "$H_a$: $\\mu_b$ != $\\mu_m$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_indResult(statistic=0.43786693335411514, pvalue=0.6615527890254489)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The data has some nonsensical datapoints, i.e. salary of 0 or 9,999,999. \n",
    "# Ignoring because it's not a data cleaning exercise.\n",
    "mas = df.AdjustedCompensation.loc[\n",
    "    (df.AdjustedCompensation.notnull()) & (df.FormalEducation == 'Master\\'s degree')\n",
    "                                 ].copy()\n",
    "bach = df.AdjustedCompensation.loc[\n",
    "    (df.AdjustedCompensation.notnull()) & (df.FormalEducation == 'Bachelor\\'s degree')\n",
    "                                 ].copy()\n",
    "stats.ttest_ind(mas, bach, equal_var=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeated Test with Outliers Removed:\n",
      "S1: Master's degree\tS2: Bachelor's degree\n",
      "Median Values: \ts1: 53539.72 \ts2: 38292.15\n",
      "Mean Values: \ts1: 63976.63 \ts2: 53744.35\n",
      "Sample sizes: \ts1: 1985 \ts2: 1103\n",
      "Welch's t-test p-value with outliers removed: 4.438820400320138e-07\n",
      "Welch's t-test p-value with outliers removed: 4.4874583271514723e-07\n"
     ]
    }
   ],
   "source": [
    "f1 = 'FormalEducation'\n",
    "f2 = 'AdjustedCompensation'\n",
    "f1c1 = \"Master's degree\"\n",
    "f1c2 = \"Bachelor's degree\"\n",
    "subset = df[(~df[f1].isnull()) & (~df[f2].isnull())]\n",
    "s1 = subset[subset[f1]==f1c1][f2]\n",
    "s2 = subset[subset[f1]==f1c2][f2]\n",
    "\n",
    "print('Repeated Test with Outliers Removed:')\n",
    "print('S1: {}\\tS2: {}'.format(f1c1, f1c2))\n",
    "outlier_threshold = 500000\n",
    "s1 = subset[(subset[f1]==f1c1) & (subset[f2]<=outlier_threshold)][f2]\n",
    "s2 = subset[(subset[f1]==f1c2) & (subset[f2]<=outlier_threshold)][f2]\n",
    "print(\"Median Values: \\ts1: {} \\ts2: {}\".format(round(s1.median(),2), round(s2.median(),2)))\n",
    "print(\"Mean Values: \\ts1: {} \\ts2: {}\".format(round(s1.mean(),2), round(s2.mean(),2)))\n",
    "print('Sample sizes: \\ts1: {} \\ts2: {}'.format(len(s1), len(s2)))\n",
    "print(\"Welch's t-test p-value with outliers removed:\", stats.ttest_ind(s1, s2)[1]/2)\n",
    "print(\"Welch's t-test p-value with outliers removed:\", flatiron_stats.p_value_welch_ttest(s1,s2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With outliers: Because the p_value is > alpha we do not reject the null hypothesis and conclude that there isn't evidence that a difference in degree between masters and bachelors make a difference in salary.\n",
    "\n",
    "Without outliers: The p_value < alpha. Reject null hyp."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wages and Education II\n",
    "\n",
    "Now perform a similar statistical test comparing the AdjustedCompensation of those with Bachelor's degrees and those with Doctorates. If you haven't already, be sure to explore the distribution of the AdjustedCompensation feature for any anomalies. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Median Values: \n",
      "s1:74131.92 \n",
      "s2:38399.4\n",
      "Sample sizes: \n",
      "s1: 967 \n",
      "s2: 1107\n",
      "Welch's t-test p-value: 0.1568238199472023\n",
      "\n",
      "\n",
      "Repeated Test with Ouliers Removed:\n",
      "Sample sizes: \n",
      "s1: 964 \n",
      "s2: 1103\n",
      "Welch's t-test p-value with outliers removed: 0.0\n"
     ]
    }
   ],
   "source": [
    "#Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wages and Education III\n",
    "\n",
    "Remember the multiple comparisons problem; rather than continuing on like this, perform an ANOVA test between the various 'FormalEducation' categories and their relation to 'AdjustedCompensation'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          sum_sq      df          F        PR(>F)\n",
      "C(FormalEducation)  5.841881e+11     6.0  29.224224  1.727132e-34\n",
      "Residual            1.439270e+13  4320.0        NaN           NaN\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "subset = df.loc[\n",
    "    (~df.AdjustedCompensation.isnull()\n",
    "     & (df.AdjustedCompensation <= 500000))\n",
    "]\n",
    "\n",
    "form = 'AdjustedCompensation ~ C(FormalEducation)'\n",
    "lm = ols(form, subset).fit()\n",
    "table = sm.stats.anova_lm(lm, typ=2)\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          sum_sq      df          F        PR(>F)\n",
      "C(FormalEducation)  5.841881e+11     6.0  29.224224  1.727132e-34\n",
      "Residual            1.439270e+13  4320.0        NaN           NaN\n"
     ]
    }
   ],
   "source": [
    "temp = df[df[f2]<=5*10**5]\n",
    "\n",
    "# This temp is equivalent\n",
    "# temp = df.loc[\n",
    "#     (~df.AdjustedCompensation.isnull()\n",
    "#      & (df.AdjustedCompensation <= 500000))\n",
    "# ]\n",
    "formula = '{} ~ C({})'.format(f2, f1)\n",
    "lm = ols(formula, temp).fit()\n",
    "table = sm.stats.anova_lm(lm, typ=2)\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional Resources\n",
    "\n",
    "Here's the original source where the data was taken from:  \n",
    "    [Kaggle Machine Learning & Data Science Survey 2017](https://www.kaggle.com/kaggle/kaggle-survey-2017)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this lab, you practiced conducting actual hypothesis tests on actual data. From this, you saw how dependent results can be on the initial problem formulation, including preprocessing!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
